# SubMaker - Stremio Subtitle Translator
# Environment Configuration

# ======================
# REQUIRED - API Keys and Server Configuration
# ======================

# OpenSubtitles Developer API Key (REQUIRED)
OPENSUBTITLES_API_KEY=

# Port to run the server on (default: 7001)
PORT=7001

# Node environment: development or production
NODE_ENV=production

# Log level: 'debug' (all logs), 'warn' (warnings + errors), 'error' (errors only)
LOG_LEVEL=error

# Storage type: "filesystem" (default) or "redis"
# Use "filesystem" for local development with npm start
# Use "redis" for production/HA deployment with Docker
STORAGE_TYPE=redis

# Encryption key for sensitive user data (API keys, passwords)
# Must be 64 hex characters (32 bytes) for AES-256-GCM encryption
# If not provided, a key will be auto-generated and saved to .encryption-key file
# Generate a key: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
# ENCRYPTION_KEY=

# ======================
# IMPORTANT - Storage Configuration
# ======================

# Redis Configuration (only needed if STORAGE_TYPE=redis)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_KEY_PREFIX=stremio

# ======================
# Redis High Availability (OPTIONAL - Enterprise Deployments)
# ======================

# Redis Sentinel for automatic failover (disabled by default)
# Only enable this for production HA deployments with Redis Sentinel
# Single-user deployments should leave this disabled
# REDIS_SENTINEL_ENABLED=false

# Sentinel configuration (only used if REDIS_SENTINEL_ENABLED=true)
# Comma-separated list of sentinel nodes (host:port)
# Example: REDIS_SENTINELS=sentinel1:26379,sentinel2:26379,sentinel3:26379
# REDIS_SENTINELS=localhost:26379

# Sentinel master name (default: mymaster)
# REDIS_SENTINEL_NAME=mymaster

# Cache Size Limits (in bytes)
# CRITICAL: Total cache size MUST be less than Redis maxmemory setting!
# Default: 3GB total (fits in 4GB Redis with 1GB overhead)
#
# For larger deployments with more RAM:
# - Set Redis maxmemory to 16GB and use: CACHE_LIMIT_TRANSLATION=6442450944 (6GB)
# - Or set to 120GB+ and increase proportionally
# - Example: CACHE_LIMIT_TRANSLATION=53687091200 (50GB) for enterprise deployments
#
# CACHE_LIMIT_TRANSLATION=1610612736  # 1.5GB (default) - permanent translations - was 6442450944 (6GB) for 16GB Redis
# CACHE_LIMIT_BYPASS=536870912        # 0.5GB (default) - temporary user cache (12h TTL) - was 2147483648 (2GB) for 16GB Redis
# CACHE_LIMIT_PARTIAL=536870912       # 0.5GB (default) - in-progress translations (1h TTL) - was 2147483648 (2GB) for 16GB Redis
# CACHE_LIMIT_SYNC=536870912          # 0.5GB (default) - synced subtitles - was 2147483648 (2GB) for 16GB Redis

# ======================
# AI Translation Configuration (ADVANCED)
# ======================

# Default Gemini model to use for translations (optional)
# If not set, defaults to gemini-2.5-flash-lite-preview-09-2025
# Examples: gemini-2.0-flash-exp, gemini-2.5-flash-latest, gemini-2.5-pro-latest
# GEMINI_MODEL=gemini-2.5-flash-lite-preview-09-2025

# Extended thinking mode for translations (default: 0 = disabled)
# Controls how many tokens the AI uses for "thinking" before responding
# - 0: Disabled (faster, uses default AI reasoning)
# - -1: Dynamic thinking (AI decides how much thinking time needed)
# - 1000-32000: Fixed token budget for thinking (higher = more careful reasoning)
# Note: Thinking tokens count toward API usage and reduce available output tokens
# Recommendation: -1 for quality, 0 for speed, >0 for controlled thinking
# GEMINI_THINKING_BUDGET=0

# Translation creativity/temperature (default: 0.8)
# Controls randomness in translations (0.0 = deterministic, 2.0 = very creative)
# - 0.0-0.3: Very consistent, literal translations
# - 0.4-0.8: Balanced - natural while staying accurate (recommended)
# - 0.9-1.5: More creative, varied phrasing
# - 1.6-2.0: Very creative, may deviate from source
# GEMINI_TEMPERATURE=0.8

# Top-K sampling for translation diversity (default: 40)
# Limits the number of highest probability tokens considered
# Lower = more focused, Higher = more diverse
# Range: 1-100, recommended: 20-60
# GEMINI_TOP_K=40

# Top-P (nucleus) sampling for translation quality (default: 0.95)
# Cumulative probability threshold for token selection
# - 0.9: More conservative, predictable translations
# - 0.95: Balanced (recommended)
# - 0.99: More diverse, creative translations
# GEMINI_TOP_P=0.95

# Maximum output tokens per API call (default: 65536)
# Limits the length of generated translations
# Note: Actual limit depends on the model (2.0 models: 8192, 2.5 models: 65536)
# GEMINI_MAX_OUTPUT_TOKENS=65536

# API timeout for translation requests in seconds (default: 600)
# How long to wait for translation API responses before timing out
# Increase for very long subtitle files or slow network connections
# GEMINI_TRANSLATION_TIMEOUT=600

# Maximum retry attempts for failed API calls (default: 3)
# Number of times to retry on 429 rate limits, 503 service unavailable, timeouts, and network errors
# Uses exponential backoff: 3s, 6s, 12s delays between retries
# Set to 0 to disable retries (fail immediately)
# GEMINI_MAX_RETRIES=3

# ======================
# Parallel Translation (ADVANCED - File Upload Page)
# ======================

# Parallel translation for large SRT files (file upload page only)
# Splits large files into chunks and translates them concurrently for better performance
# Each chunk includes context from surrounding entries to maintain translation coherence

# Token threshold to enable parallel translation (default: 15000)
# Files larger than this will be split into chunks and translated in parallel
# Files smaller than this use a single API call
# Set higher to use single-call more often, lower to use parallel more often
# PARALLEL_TRANSLATION_THRESHOLD=15000

# Maximum concurrent API calls (default: 3)
# How many chunks to translate simultaneously
# Higher = faster but more API quota usage and potential rate limiting
# Recommended: 3-5 for Gemini API (avoid rate limits)
# PARALLEL_MAX_CONCURRENCY=3

# Target tokens per chunk (default: 12000)
# Each chunk will aim for this many tokens (chunks may be slightly larger/smaller)
# Should be well below model's max input tokens to leave room for prompts and context
# Recommended: 10000-15000 for most Gemini models
# PARALLEL_CHUNK_SIZE=12000

# Context overlap size (default: 3)
# Number of subtitle entries to include from previous/next chunks for context
# Higher = better coherence across chunks, but more redundant processing
# Recommended: 2-4 entries
# PARALLEL_CONTEXT_SIZE=3

# ======================
# Performance Tuning (ADVANCED)
# ======================

# Subtitle Search Cache (in-memory, user-scoped)
# Caches subtitle search results from providers (OpenSubtitles, SubDL, SubSource)
# Each user gets their own isolated cache based on their config
# Cache automatically purges when user changes their configuration
# SUBTITLE_SEARCH_CACHE_MAX=15000           # Max cached searches (default: 15000)
# SUBTITLE_SEARCH_CACHE_TTL_MS=900000       # Cache lifetime in ms (default: 900000 = 15 minutes)

# Entry cache size (default: 100000)
# In-memory cache for individual subtitle entries
# Higher values = better cache hit rates but more RAM usage
# Estimate: 100K entries â‰ˆ 10-20MB RAM
# ENTRY_CACHE_SIZE=100000

# Partial cache flush timing (adaptive - optimized for user experience)
# First partial save: Quick initial feedback (default: 15000 = 15 seconds)
# Subsequent saves: Reduced I/O frequency (default: 30000 = 30 seconds)
#
# PARTIAL_FIRST_FLUSH_MS=15000      # First partial delivery (quick user feedback)
# PARTIAL_FLUSH_INTERVAL_MS=30000   # Subsequent partial deliveries (reduced I/O)

# ======================
# Session Management
# ======================

# Session expiration time in milliseconds (sliding expiration - resets on each use)
# Default: 7776000000 (90 days / 3 months)
# Sessions only expire after this period of complete inactivity
SESSION_MAX_AGE=7776000000

# Auto-save interval for session persistence (in milliseconds)
# How often to save sessions to disk
# Default: 300000 (5 minutes)
SESSION_SAVE_INTERVAL=300000

# Path to store session data on disk
# Sessions are saved here and reloaded on server restart
# Default: ./data/sessions.json
SESSION_PERSISTENCE_PATH=./data/sessions.json

# Session store is unbounded by count by default.
# To enforce a cap, set MAX_SESSIONS to a positive integer.
# Example:
# MAX_SESSIONS=1000

# ======================
# Security Configuration
# ======================

# Force session-based authentication even on localhost
# Set to 'true' to disable base64 encoding on localhost (for testing production behavior)
# Default: not set (allows base64 on localhost for development convenience)
# FORCE_SESSIONS=true

# Allow base64-encoded configs in production (NOT RECOMMENDED)
# Only enable this if you need backward compatibility
# Default: not set (base64 configs disabled in production)
# ALLOW_BASE64_CONFIG=true

# ======================
# Logging Configuration
# ======================

# Write logs to file (enabled by default in production)
# Set to 'false' to disable file logging even in production
# Default: true in production, false in development
# LOG_TO_FILE=true

# Directory for log files (default: ./logs)
# LOG_DIR=./logs

# Log file name (default: app.log)
# LOG_BASENAME=app.log

# Maximum size of a single log file in MB (default: 10)
# LOG_MAX_SIZE_MB=10

# Maximum number of archived log files to keep (default: 100)
# LOG_MAX_FILES=100

# Maximum age of log files in days before auto-deletion (default: 14)
# LOG_MAX_AGE_DAYS=14

# ======================
# High-Performance Logging
# ======================

# Log sampling rate for high-load scenarios (0.0 to 1.0, default: 1.0 = no sampling)
# Example: 0.1 = log only 10% of messages (reduces I/O and CPU overhead)
# Useful for HA deployments with thousands of requests per second
# LOG_SAMPLE_RATE=1.0

# Only sample debug logs (default: false)
# When true, only debug logs are sampled; warn/error logs are always logged
# Recommended for production: set to true to ensure critical messages aren't lost
# LOG_SAMPLE_DEBUG_ONLY=true

# ======================
# Production Deployment
# ======================

# For VPS deployment, set these:
# NODE_ENV=production
# PORT=7001
# SESSION_MAX_AGE=7776000000

# Make sure your reverse proxy (nginx/apache) passes these headers:
# - X-Forwarded-Proto (for HTTPS detection)
# - X-Forwarded-For (for rate limiting)

# ======================
# Development/Testing
# ======================

# For local development, you can use defaults:
# NODE_ENV=development
# PORT=7001

# To test production session behavior on localhost:
# FORCE_SESSIONS=true

# ======================
# Branding Configuration
# ======================

# ElfHosted branding
# When enabled, addon name in Stremio will appear as "SubMaker | ElfHosted"
# This is used for the public ElfHosted instance at https://submaker.elfhosted.com
# ELFHOSTED=true